{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import root_numpy\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_multiclass_auc(data):\n",
    "    train = data[0]\n",
    "    test = data[1]\n",
    "    clf = clone(data[2])\n",
    "    X_train = train.drop('target', axis=1).values\n",
    "    y_train = train['target'].values\n",
    "\n",
    "    X_test = test.drop('target', axis=1).values\n",
    "    y_test = test['target'].values\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    return [1 - roc_auc_score(y_test > 0, y_pred[:, 0] / y_pred[:, 1],\n",
    "                                                      sample_weight=(y_test != 2) * 1),\n",
    "    1 - roc_auc_score(y_test > 1, y_pred[:, 0] / y_pred[:, 2],\n",
    "                                                      sample_weight=(y_test != 1) * 1),\n",
    "    1 - roc_auc_score(y_test > 1, y_pred[:, 1] / y_pred[:, 2],\n",
    "                                                      sample_weight=(y_test != 0) * 1)]\n",
    "\n",
    "def compute_auc(data):\n",
    "    train = data[0]\n",
    "    test = data[1]\n",
    "    clf = clone(data[2])\n",
    "    X_train = train.drop('target', axis=1).values\n",
    "    y_train = train['target'].values\n",
    "\n",
    "    X_test = test.drop('target', axis=1).values\n",
    "    y_test = test['target'].values\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    return roc_auc_score(y_test, y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treename = 'tag'\n",
    "\n",
    "data_b = pd.DataFrame(root_numpy.root2array('datasets/type=5.root', treename=treename)).dropna()\n",
    "data_b = data_b[::20].reset_index(drop=True)\n",
    "data_c = pd.DataFrame(root_numpy.root2array('datasets/type=4.root', treename=treename)).dropna().reset_index(drop=True)\n",
    "data_light = pd.DataFrame(root_numpy.root2array('datasets/type=0.root', treename=treename)).dropna().reset_index(drop=True)\n",
    "data_b['target'] = 0\n",
    "data_c['target'] = 1\n",
    "data_light['target'] = 2\n",
    "data = {'b': data_b, 'c': data_c, 'light': data_light}\n",
    "jet_features = [column for column in data_b.columns if \"Jet\" in column]\n",
    "sv_features = [column for column in data_b.columns if \"SV\" in column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in data.values():\n",
    "    features = []\n",
    "    for ind1 in range(0, len(sv_features)):\n",
    "        f1 = sv_features[ind1]\n",
    "        for ind2 in range(ind1, len(sv_features)):\n",
    "            f2 = sv_features[ind2]\n",
    "            d[f1+'_mult_'+f2] = d[f1].values * d[f2].values\n",
    "            d[f1+'_div_'+f2] = d[f1].values / (d[f2].values + 0.1)\n",
    "            #d[f2+'_div_'+f1] = d[f2].values / (d[f1].values + 0.1)\n",
    "            features.append(f1+'_mult_'+f2)\n",
    "            features.append(f1+'_div_'+f2)\n",
    "            #features.append(f2+'_div_'+f1)\n",
    "            #d['2'+f1+'_mult_'+f2] = (d[f1].values**2) * (d[f2].values**2)\n",
    "            #d['2'+f1+'_div_'+f2] = (d[f1].values**2) / (d[f2].values**2 + 0.1)\n",
    "            d['2'+f1+'_plus_'+f2] = (d[f1].values**2) + (d[f2].values**2)\n",
    "            #['2'+f1+'_min_'+f2] = (d[f1].values**2) - (d[f2].values**2)\n",
    "            #features.append('2'+f1+'_mult_'+f2)\n",
    "            #features.append('2'+f1+'_div_'+f2)\n",
    "            features.append('2'+f1+'_plus_'+f2)\n",
    "            #features.append('2'+f1+'_min_'+f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_b_c = pd.concat([data_b, data_c], ignore_index=True)\n",
    "data_b_c = data_b_c.iloc[np.random.permutation(len(data_b_c))]\n",
    "\n",
    "data_b_light = pd.concat([data_b, data_light], ignore_index=True)\n",
    "data_b_light = data_b_light.iloc[np.random.permutation(len(data_b_light))]\n",
    "data_b_light.loc[data_b_light['target'] == 2, 'target'] = 1\n",
    "\n",
    "data_c_light = pd.concat([data_c, data_light], ignore_index=True)\n",
    "data_c_light = data_c_light.iloc[np.random.permutation(len(data_c_light))]\n",
    "data_c_light.loc[data_c_light['target'] == 1, 'target'] = 0\n",
    "data_c_light.loc[data_c_light['target'] == 2, 'target'] = 1\n",
    "\n",
    "data_bc_light = pd.concat([data_b, data_c, data_light], ignore_index=True)\n",
    "data_bc_light = data_bc_light.iloc[np.random.permutation(len(data_bc_light))]\n",
    "data_bc_light.loc[data_bc_light['target'] == 1, 'target'] = 0\n",
    "data_bc_light.loc[data_bc_light['target'] == 2, 'target'] = 1\n",
    "\n",
    "data_b_c_light = pd.concat([data_b, data_c, data_light], ignore_index=True)\n",
    "data_b_c_light = data_b_c_light.iloc[np.random.permutation(len(data_b_c_light))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xclf1 = xgb.XGBClassifier(learning_rate=0.02,\n",
    "                         max_depth=7,\n",
    "                         n_estimators=600,\n",
    "                         gamma=2.0,\n",
    "                         objective='binary:logistic',\n",
    "                         colsample_bytree=0.55,\n",
    "                         subsample=0.55,\n",
    "                         min_child_weight=2)\n",
    "\n",
    "xclf2 = xgb.XGBClassifier(learning_rate=0.02,\n",
    "                         max_depth=6,\n",
    "                         n_estimators=2000,\n",
    "                         gamma=2,\n",
    "                         objective='binary:logistic',\n",
    "                         colsample_bytree=0.85,\n",
    "                         subsample=0.65,\n",
    "                         min_child_weight=2)\n",
    "\n",
    "xclf3 = xgb.XGBClassifier(learning_rate=0.02,\n",
    "                         max_depth=5,\n",
    "                         n_estimators=1000,\n",
    "                         gamma=2.5,\n",
    "                         objective='binary:logistic',\n",
    "                         colsample_bytree=0.85,\n",
    "                         subsample=0.65,\n",
    "                         min_child_weight=2)\n",
    "\n",
    "xclf4 = xgb.XGBClassifier(learning_rate=0.02,\n",
    "                         max_depth=6,\n",
    "                         n_estimators=2000,\n",
    "                         gamma=2.5,\n",
    "                         objective='binary:logistic',\n",
    "                         colsample_bytree=0.85,\n",
    "                         subsample=0.65,\n",
    "                         min_child_weight=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn(dataset, clf, estimator):\n",
    "    foldation = KFold(dataset.shape[0], 2, shuffle=True, random_state=0)\n",
    "    pool = multiprocessing.Pool(4)\n",
    "    output = pool.map(estimator, [(dataset[sv_features + features + ['target']].iloc[train_index], dataset[sv_features + features + ['target']].iloc[test_index], clf)\n",
    "        for train_index, test_index in foldation])\n",
    "    pool.close()\n",
    "    return np.mean(output, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95139229,  0.9888575 ,  0.98096004])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn(data_b_c_light, xclf1, compute_multiclass_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
